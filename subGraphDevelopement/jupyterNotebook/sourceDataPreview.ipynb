{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e58c4a-2df5-46a3-b4f8-430ce00a75de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /Users/pegz/Desktop/BachelorProject/BA_Thesis/subGraphDevelopement/.venv/lib/python3.13/site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /Users/pegz/Desktop/BachelorProject/BA_Thesis/subGraphDevelopement/.venv/lib/python3.13/site-packages (from scipy) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6650abd3-630e-4347-8693-f1be397c75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/pegz/Desktop/BachelorProject/BA_Thesis/subGraphDevelopement/.venv/lib/python3.13/site-packages (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391c3653-3d05-45e4-8f7a-9e576703a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "def getSourceData ():\n",
    "    \n",
    "    # Load the .mat file\n",
    "    mat_data = sio.loadmat('/Users/pegz/Desktop/BachelorProject/BA_Thesis/subGraphDevelopement/MatPreprocs/EEG_MDD_Kij_matrices.mat')\n",
    "    \n",
    "    alpha_responder_day0 = mat_data['alpha_window_Kij_resp176_1']\n",
    "    alpha_responder_day7 = mat_data['alpha_window_Kij_resp176_2']\n",
    "    alpha_non_responder_day0 = mat_data['alpha_window_Kij_non_resp176_1']\n",
    "    alpha_non_responder_day7 = mat_data['alpha_window_Kij_non_resp176_2']\n",
    "    \n",
    "    # Access the gender vector\n",
    "    sex = mat_data['sex']\n",
    "    return alpha_responder_day0, alpha_responder_day7, alpha_non_responder_day0, alpha_non_responder_day7, sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34349f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMatrix(matrix):\n",
    "    output_file_path = 'matrix_output.txt'\n",
    "\n",
    "    # Open the file in write mode\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        # Iterate over each row in the matrix\n",
    "        for row in matrix:\n",
    "            # Convert the row to a string and write it to the file\n",
    "            row_str = '[' + ' '.join(map(str, row)) + ']'\n",
    "            file.write(row_str + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53309f1e-60d6-457a-988c-dd98c5d4aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSamplesRand(alpha_responder_day0):\n",
    "    # Select random samples (subject, window) to print\n",
    "    n_subjects = alpha_responder_day0.shape[0]\n",
    "    n_windows = alpha_responder_day0.shape[3]\n",
    "\n",
    "    # Print 10 samples (random subjects and windows)\n",
    "    for sample_num in range(10):\n",
    "        # Random subject and window\n",
    "        subject_idx = np.random.randint(n_subjects)\n",
    "        window_idx = np.random.randint(n_windows)\n",
    "        \n",
    "        # Get the corresponding 19x19 coupling matrix\n",
    "        \n",
    "        coupling_matrix = alpha_responder_day0[subject_idx, :, :, window_idx]\n",
    "        \n",
    "        print(f\"Sample {sample_num+1}: Subject {subject_idx}, Window {window_idx}\")\n",
    "        printMatrix(coupling_matrix)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c405cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Subject 31, Window 34\n",
      "\n",
      "\n",
      "Sample 2: Subject 79, Window 122\n",
      "\n",
      "\n",
      "Sample 3: Subject 44, Window 52\n",
      "\n",
      "\n",
      "Sample 4: Subject 40, Window 96\n",
      "\n",
      "\n",
      "Sample 5: Subject 5, Window 40\n",
      "\n",
      "\n",
      "Sample 6: Subject 55, Window 6\n",
      "\n",
      "\n",
      "Sample 7: Subject 81, Window 42\n",
      "\n",
      "\n",
      "Sample 8: Subject 55, Window 82\n",
      "\n",
      "\n",
      "Sample 9: Subject 40, Window 26\n",
      "\n",
      "\n",
      "Sample 10: Subject 58, Window 62\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha_responder_day0, alpha_responder_day7, alpha_non_responder_day0, alpha_non_responder_day7, sex = getSourceData()\n",
    "printSamplesRand (alpha_responder_day0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cb94e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSamples(alpha_responder_day0):\n",
    "    # Select random samples (subject, window) to print\n",
    "    n_subjects = alpha_responder_day0.shape[0]\n",
    "    n_windows = alpha_responder_day0.shape[3]\n",
    "\n",
    "    subject_idx = np.random.randint(n_subjects)\n",
    "    window_idx = np.random.randint(n_windows)\n",
    "    subject_data = alpha_responder_day0[subject_idx]\n",
    "    \n",
    "    formatted_data = []\n",
    "    formatted_data.append(f\"t # {subject_idx}\")\n",
    "    \n",
    "    matrix = subject_data[:, :, window_idx]  # Extract individual 19x19 matrix for the current window\n",
    "    \n",
    "    num_vertices = matrix.shape[0]  # Should be 19 for EEG channels \n",
    "    vertex_label = 1000  # Arbitrary label for the vertices   \n",
    "    for vertex in range(num_vertices):\n",
    "        formatted_data.append(f\"v {vertex} {vertex_label}\")\n",
    "\n",
    "    for i in range(num_vertices):\n",
    "        for j in range(num_vertices):\n",
    "            if i != j:\n",
    "                edge_value = matrix[i, j]\n",
    "                # Only include edges with a weight above the threshold\n",
    "                if edge_value > 1:\n",
    "                    formatted_data.append(f\"e {i} {j} {int(edge_value)}\")\n",
    "                else:\n",
    "                    formatted_data.append(f\"e {i} {j} {int(2)}\")\n",
    "                    \n",
    "    print(f\"num_vertices {num_vertices}: Subject {subject_idx}, Window {window_idx}\")\n",
    "    printMatrix(matrix)\n",
    "    print(\"\\n\".join(formatted_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0383628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_vertices 19: Subject 61, Window 13\n",
      "t # 61\n",
      "v 0 1000\n",
      "v 1 1000\n",
      "v 2 1000\n",
      "v 3 1000\n",
      "v 4 1000\n",
      "v 5 1000\n",
      "v 6 1000\n",
      "v 7 1000\n",
      "v 8 1000\n",
      "v 9 1000\n",
      "v 10 1000\n",
      "v 11 1000\n",
      "v 12 1000\n",
      "v 13 1000\n",
      "v 14 1000\n",
      "v 15 1000\n",
      "v 16 1000\n",
      "v 17 1000\n",
      "v 18 1000\n",
      "e 0 1 30\n",
      "e 0 2 2\n",
      "e 0 3 46\n",
      "e 0 4 47\n",
      "e 0 5 2\n",
      "e 0 6 20\n",
      "e 0 7 71\n",
      "e 0 8 71\n",
      "e 0 9 43\n",
      "e 0 10 2\n",
      "e 0 11 135\n",
      "e 0 12 183\n",
      "e 0 13 2\n",
      "e 0 14 24\n",
      "e 0 15 2\n",
      "e 0 16 2\n",
      "e 0 17 30\n",
      "e 0 18 71\n",
      "e 1 0 2\n",
      "e 1 2 2\n",
      "e 1 3 89\n",
      "e 1 4 136\n",
      "e 1 5 2\n",
      "e 1 6 87\n",
      "e 1 7 47\n",
      "e 1 8 69\n",
      "e 1 9 20\n",
      "e 1 10 2\n",
      "e 1 11 173\n",
      "e 1 12 177\n",
      "e 1 13 13\n",
      "e 1 14 12\n",
      "e 1 15 2\n",
      "e 1 16 2\n",
      "e 1 17 95\n",
      "e 1 18 97\n",
      "e 2 0 973\n",
      "e 2 1 2\n",
      "e 2 3 239\n",
      "e 2 4 2\n",
      "e 2 5 186\n",
      "e 2 6 46\n",
      "e 2 7 70\n",
      "e 2 8 218\n",
      "e 2 9 293\n",
      "e 2 10 336\n",
      "e 2 11 119\n",
      "e 2 12 103\n",
      "e 2 13 10\n",
      "e 2 14 13\n",
      "e 2 15 168\n",
      "e 2 16 136\n",
      "e 2 17 138\n",
      "e 2 18 2\n",
      "e 3 0 123\n",
      "e 3 1 2\n",
      "e 3 2 7\n",
      "e 3 4 2\n",
      "e 3 5 2\n",
      "e 3 6 2\n",
      "e 3 7 2\n",
      "e 3 8 2\n",
      "e 3 9 12\n",
      "e 3 10 2\n",
      "e 3 11 1\n",
      "e 3 12 147\n",
      "e 3 13 2\n",
      "e 3 14 2\n",
      "e 3 15 2\n",
      "e 3 16 2\n",
      "e 3 17 2\n",
      "e 3 18 2\n",
      "e 4 0 205\n",
      "e 4 1 298\n",
      "e 4 2 112\n",
      "e 4 3 2\n",
      "e 4 5 2\n",
      "e 4 6 2\n",
      "e 4 7 243\n",
      "e 4 8 2\n",
      "e 4 9 348\n",
      "e 4 10 2\n",
      "e 4 11 61\n",
      "e 4 12 2\n",
      "e 4 13 2\n",
      "e 4 14 44\n",
      "e 4 15 2\n",
      "e 4 16 507\n",
      "e 4 17 2\n",
      "e 4 18 2\n",
      "e 5 0 196\n",
      "e 5 1 2\n",
      "e 5 2 2\n",
      "e 5 3 109\n",
      "e 5 4 2\n",
      "e 5 6 38\n",
      "e 5 7 2\n",
      "e 5 8 2\n",
      "e 5 9 87\n",
      "e 5 10 10\n",
      "e 5 11 57\n",
      "e 5 12 78\n",
      "e 5 13 2\n",
      "e 5 14 2\n",
      "e 5 15 28\n",
      "e 5 16 2\n",
      "e 5 17 2\n",
      "e 5 18 2\n",
      "e 6 0 122\n",
      "e 6 1 2\n",
      "e 6 2 2\n",
      "e 6 3 92\n",
      "e 6 4 2\n",
      "e 6 5 2\n",
      "e 6 7 232\n",
      "e 6 8 2\n",
      "e 6 9 2\n",
      "e 6 10 2\n",
      "e 6 11 50\n",
      "e 6 12 2\n",
      "e 6 13 2\n",
      "e 6 14 2\n",
      "e 6 15 2\n",
      "e 6 16 73\n",
      "e 6 17 2\n",
      "e 6 18 326\n",
      "e 7 0 578\n",
      "e 7 1 2\n",
      "e 7 2 2\n",
      "e 7 3 205\n",
      "e 7 4 11\n",
      "e 7 5 293\n",
      "e 7 6 128\n",
      "e 7 8 2\n",
      "e 7 9 288\n",
      "e 7 10 390\n",
      "e 7 11 2\n",
      "e 7 12 2\n",
      "e 7 13 2\n",
      "e 7 14 2\n",
      "e 7 15 193\n",
      "e 7 16 2\n",
      "e 7 17 95\n",
      "e 7 18 2\n",
      "e 8 0 62\n",
      "e 8 1 143\n",
      "e 8 2 14\n",
      "e 8 3 58\n",
      "e 8 4 7\n",
      "e 8 5 164\n",
      "e 8 6 20\n",
      "e 8 7 137\n",
      "e 8 9 157\n",
      "e 8 10 19\n",
      "e 8 11 97\n",
      "e 8 12 2\n",
      "e 8 13 2\n",
      "e 8 14 2\n",
      "e 8 15 2\n",
      "e 8 16 230\n",
      "e 8 17 2\n",
      "e 8 18 128\n",
      "e 9 0 2\n",
      "e 9 1 199\n",
      "e 9 2 2\n",
      "e 9 3 2\n",
      "e 9 4 56\n",
      "e 9 5 54\n",
      "e 9 6 2\n",
      "e 9 7 2\n",
      "e 9 8 2\n",
      "e 9 10 88\n",
      "e 9 11 2\n",
      "e 9 12 2\n",
      "e 9 13 11\n",
      "e 9 14 2\n",
      "e 9 15 142\n",
      "e 9 16 2\n",
      "e 9 17 2\n",
      "e 9 18 2\n",
      "e 10 0 134\n",
      "e 10 1 2\n",
      "e 10 2 5\n",
      "e 10 3 74\n",
      "e 10 4 59\n",
      "e 10 5 2\n",
      "e 10 6 2\n",
      "e 10 7 2\n",
      "e 10 8 140\n",
      "e 10 9 2\n",
      "e 10 11 144\n",
      "e 10 12 129\n",
      "e 10 13 2\n",
      "e 10 14 2\n",
      "e 10 15 2\n",
      "e 10 16 2\n",
      "e 10 17 217\n",
      "e 10 18 110\n",
      "e 11 0 2\n",
      "e 11 1 622\n",
      "e 11 2 2\n",
      "e 11 3 2\n",
      "e 11 4 2\n",
      "e 11 5 2\n",
      "e 11 6 212\n",
      "e 11 7 27\n",
      "e 11 8 36\n",
      "e 11 9 4\n",
      "e 11 10 2\n",
      "e 11 12 168\n",
      "e 11 13 2\n",
      "e 11 14 2\n",
      "e 11 15 69\n",
      "e 11 16 189\n",
      "e 11 17 2\n",
      "e 11 18 2\n",
      "e 12 0 231\n",
      "e 12 1 2\n",
      "e 12 2 2\n",
      "e 12 3 49\n",
      "e 12 4 65\n",
      "e 12 5 2\n",
      "e 12 6 61\n",
      "e 12 7 2\n",
      "e 12 8 83\n",
      "e 12 9 224\n",
      "e 12 10 2\n",
      "e 12 11 131\n",
      "e 12 13 2\n",
      "e 12 14 7\n",
      "e 12 15 77\n",
      "e 12 16 2\n",
      "e 12 17 62\n",
      "e 12 18 26\n",
      "e 13 0 599\n",
      "e 13 1 2\n",
      "e 13 2 2\n",
      "e 13 3 159\n",
      "e 13 4 74\n",
      "e 13 5 213\n",
      "e 13 6 471\n",
      "e 13 7 39\n",
      "e 13 8 2\n",
      "e 13 9 2\n",
      "e 13 10 1028\n",
      "e 13 11 134\n",
      "e 13 12 2\n",
      "e 13 14 24\n",
      "e 13 15 468\n",
      "e 13 16 2\n",
      "e 13 17 457\n",
      "e 13 18 2\n",
      "e 14 0 499\n",
      "e 14 1 352\n",
      "e 14 2 127\n",
      "e 14 3 9\n",
      "e 14 4 2\n",
      "e 14 5 2\n",
      "e 14 6 2\n",
      "e 14 7 176\n",
      "e 14 8 2\n",
      "e 14 9 349\n",
      "e 14 10 2\n",
      "e 14 11 2\n",
      "e 14 12 2\n",
      "e 14 13 2\n",
      "e 14 15 2\n",
      "e 14 16 3\n",
      "e 14 17 2\n",
      "e 14 18 282\n",
      "e 15 0 177\n",
      "e 15 1 2\n",
      "e 15 2 2\n",
      "e 15 3 28\n",
      "e 15 4 23\n",
      "e 15 5 148\n",
      "e 15 6 36\n",
      "e 15 7 2\n",
      "e 15 8 2\n",
      "e 15 9 2\n",
      "e 15 10 216\n",
      "e 15 11 2\n",
      "e 15 12 2\n",
      "e 15 13 2\n",
      "e 15 14 2\n",
      "e 15 16 2\n",
      "e 15 17 2\n",
      "e 15 18 2\n",
      "e 16 0 637\n",
      "e 16 1 2\n",
      "e 16 2 2\n",
      "e 16 3 177\n",
      "e 16 4 2\n",
      "e 16 5 59\n",
      "e 16 6 71\n",
      "e 16 7 233\n",
      "e 16 8 48\n",
      "e 16 9 48\n",
      "e 16 10 124\n",
      "e 16 11 160\n",
      "e 16 12 135\n",
      "e 16 13 2\n",
      "e 16 14 8\n",
      "e 16 15 2\n",
      "e 16 17 67\n",
      "e 16 18 24\n",
      "e 17 0 552\n",
      "e 17 1 2\n",
      "e 17 2 32\n",
      "e 17 3 46\n",
      "e 17 4 2\n",
      "e 17 5 48\n",
      "e 17 6 36\n",
      "e 17 7 236\n",
      "e 17 8 2\n",
      "e 17 9 34\n",
      "e 17 10 163\n",
      "e 17 11 136\n",
      "e 17 12 187\n",
      "e 17 13 6\n",
      "e 17 14 8\n",
      "e 17 15 32\n",
      "e 17 16 2\n",
      "e 17 18 19\n",
      "e 18 0 119\n",
      "e 18 1 2\n",
      "e 18 2 2\n",
      "e 18 3 79\n",
      "e 18 4 93\n",
      "e 18 5 2\n",
      "e 18 6 6\n",
      "e 18 7 2\n",
      "e 18 8 34\n",
      "e 18 9 2\n",
      "e 18 10 2\n",
      "e 18 11 131\n",
      "e 18 12 2\n",
      "e 18 13 2\n",
      "e 18 14 2\n",
      "e 18 15 2\n",
      "e 18 16 2\n",
      "e 18 17 113\n"
     ]
    }
   ],
   "source": [
    "alpha_responder_day0, alpha_responder_day7, alpha_non_responder_day0, alpha_non_responder_day7, sex = getSourceData()\n",
    "printSamples (alpha_responder_day0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21c76fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved resp_day0 data to graph.data.resp_day0\n",
      "Saved resp_day7 data to graph.data.resp_day7\n",
      "Saved nonresp_day0 data to graph.data.nonresp_day0\n",
      "Saved nonresp_day7 data to graph.data.nonresp_day7\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def src_dict_5Sample ():\n",
    "\n",
    "    # Load the .mat file\n",
    "    mat_data = sio.loadmat('/Users/pegz/Desktop/BachelorProject/BA_Thesis/subGraphDevelopement/MatPreprocs/EEG_MDD_Kij_matrices.mat')\n",
    "\n",
    "    # Extract matrices from mat_data\n",
    "    alpha_responder_day0 = mat_data['alpha_window_Kij_resp176_1']\n",
    "    alpha_responder_day7 = mat_data['alpha_window_Kij_resp176_2']\n",
    "    alpha_non_responder_day0 = mat_data['alpha_window_Kij_non_resp176_1']\n",
    "    alpha_non_responder_day7 = mat_data['alpha_window_Kij_non_resp176_2']\n",
    "    sex = mat_data['sex']\n",
    "\n",
    "    # Initialize the dictionary structure to store the samples\n",
    "    src_dict = {\n",
    "        'resp': {\n",
    "            'day0': alpha_responder_day0,  # First 5 samples from responder Day 0\n",
    "            'day7': alpha_responder_day7   # First 5 samples from responder Day 7\n",
    "        },\n",
    "        'nonresp': {\n",
    "            'day0': alpha_non_responder_day0,  # First 5 samples from non-responder Day 0\n",
    "            'day7': alpha_non_responder_day7   # First 5 samples from non-responder Day 7\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return src_dict\n",
    "\n",
    "# Function to format matrices for gSpan, with responder/non-responder labels\n",
    "def format_matrices(matrices, vertex_label):\n",
    "    formatted_data = []\n",
    "    graphCounter = 0\n",
    "    for graph_index, subject_data in enumerate(matrices):\n",
    "        for window_idx in range(subject_data.shape[2]):  # Iterating over windows\n",
    "            matrix = subject_data[:, :, window_idx]\n",
    "            formatted_data.append(f\"t # {graphCounter}\")\n",
    "            \n",
    "            num_vertices = matrix.shape[0]  # Should be 19 for EEG channels  \n",
    "            # Add vertices with responder or non-responder label\n",
    "            for vertex in range(num_vertices):\n",
    "                formatted_data.append(f\"v {vertex} {vertex_label}\") \n",
    "\n",
    "            edge_threshold = 1\n",
    "            for i in range(num_vertices):\n",
    "                for j in range(num_vertices):\n",
    "                    if i != j:\n",
    "                        edge_value = matrix[i, j]\n",
    "\n",
    "                        # Only include edges with a weight above the threshold\n",
    "                        if edge_value > edge_threshold:\n",
    "                            formatted_data.append(f\"e {i} {j} {int(edge_value)}\")\n",
    "                    #     else:\n",
    "                    #         formatted_data.append(f\"e {i} {j} {int(10)}\")\n",
    "                    # else:\n",
    "                    #     formatted_data.append(f\"e {i} {j} {int(10)}\")\n",
    "            graphCounter += 1\n",
    "            \n",
    "    return \"\\n\".join(formatted_data)\n",
    "\n",
    "\n",
    "# Function to save formatted graph data to files\n",
    "def save_formatted_data(formatted_data, filename):\n",
    "    os.makedirs('graphdata', exist_ok=True)\n",
    "    file_path = os.path.join('graphdata', filename)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(formatted_data + \"\\nt # -1\")\n",
    "\n",
    "def save_gSpanFormat(src_dict):\n",
    "        # Format and save each dataset to separate files\n",
    "    formatted_data = {\n",
    "        'resp_day0': format_matrices(src_dict['resp']['day0'], vertex_label=100),\n",
    "        'resp_day7': format_matrices(src_dict['resp']['day7'], vertex_label=100),\n",
    "        'nonresp_day0': format_matrices(src_dict['nonresp']['day0'], vertex_label=10),\n",
    "        'nonresp_day7': format_matrices(src_dict['nonresp']['day7'], vertex_label=10)\n",
    "    }\n",
    "\n",
    "    # Save each formatted dataset to a separate file\n",
    "    save_formatted_data(formatted_data['resp_day0'], 'graph.data.resp_day0')\n",
    "    print(f\"Saved resp_day0 data to graph.data.resp_day0\")\n",
    "    \n",
    "    save_formatted_data(formatted_data['resp_day7'], 'graph.data.resp_day7')\n",
    "    print(f\"Saved resp_day7 data to graph.data.resp_day7\")\n",
    "\n",
    "    save_formatted_data(formatted_data['nonresp_day0'], 'graph.data.nonresp_day0')\n",
    "    print(f\"Saved nonresp_day0 data to graph.data.nonresp_day0\")\n",
    "\n",
    "    save_formatted_data(formatted_data['nonresp_day7'], 'graph.data.nonresp_day7')\n",
    "    print(f\"Saved nonresp_day7 data to graph.data.nonresp_day7\")\n",
    "\n",
    "\n",
    "# Execute formatting and saving\n",
    "src_dict = src_dict_5Sample()\n",
    "save_gSpanFormat(src_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80946f8",
   "metadata": {},
   "source": [
    "# Problem Breakdown\n",
    "\n",
    "1. **You have four data matrices:**\n",
    "    - Responders (Day 0): `alpha_window_Kij_responder_data176_1` (84 subjects)\n",
    "    - Responders (Day 7): `alpha_window_Kij_responder_data176_2` (84 subjects)\n",
    "    - Non-Responders (Day 0): `alpha_window_Kij_non_responder_data176_1` (92 subjects)\n",
    "    - Non-Responders (Day 7): `alpha_window_Kij_non_responder_data176_2` (92 subjects)\n",
    "\n",
    "2. **The matrices have dimensions (n, c, c, w) where:**\n",
    "    - `n`: Number of subjects\n",
    "    - `c`: Number of EEG channels (19)\n",
    "    - `w`: Number of windows (133)\n",
    "\n",
    "3. **The goal is to efficiently store and label each matrix for graph analysis, possibly distinguishing between responders and non-responders.**\n",
    "\n",
    "## Efficient Storage and Use of Responder and Non-Responder Values\n",
    "\n",
    "To efficiently store the responder and non-responder values for each matrix, we can create a structure that:\n",
    "\n",
    "- Combines the responder and non-responder matrices into a unified dataset.\n",
    "- Labels each subject based on their responder or non-responder status.\n",
    "- Indexes each matrix so that during analysis (such as with gSpan), you can quickly access the coupling matrices and the corresponding labels (responder/non-responder).\n",
    "\n",
    "## Approach\n",
    "\n",
    "1. **Create a unified dataset that includes both responder and non-responder matrices.**\n",
    "2. **Assign a label to each subject (1 for responders, 0 for non-responders).**\n",
    "3. **Track the gender (male or female) using the sex vector provided.**\n",
    "\n",
    "## Steps to Implement\n",
    "\n",
    "1. **Merge the Data:**\n",
    "    - Combine responders and non-responders from both days (Day 0 and Day 7) into a unified dataset.\n",
    "\n",
    "2. **Create Labels:**\n",
    "    - Assign 1 for responders and 0 for non-responders.\n",
    "    - Assign 1 for males and 0 for females based on the sex vector.\n",
    "\n",
    "3. **Efficient Data Structure:**\n",
    "    - Use a dictionary or a list of dictionaries to store the coupling matrices, along with their corresponding labels (responder status and gender)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b5d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_combined_data():\n",
    "    # Load data (assuming data is loaded from .mat file)\n",
    "    a_resp_day0 = mat_data['alpha_window_Kij_resp176_1']  # Responder data day 0\n",
    "    a_resp_day7 = mat_data['alpha_window_Kij_resp176_2']  # Responder data day 7\n",
    "    a_nresp_day0 = mat_data['alpha_window_Kij_non_resp176_1']  # Non-responder data day 0\n",
    "    a_nresp_day7 = mat_data['alpha_window_Kij_non_resp176_2']  # Non-responder data day 7\n",
    "    sex = mat_data['sex'].flatten()  # Gender vector\n",
    "\n",
    "    # Create labels for responders and non-responders (1 for responder, 0 for non-responder)\n",
    "    responder_labels = np.ones(a_resp_day0.shape[0])  # 1 for responders\n",
    "    non_responder_labels = np.zeros(a_nresp_day0.shape[0])  # 0 for non-responders\n",
    "\n",
    "    # Combine responder and non-responder data into a unified structure for Day 0 and Day 7\n",
    "    data_day0 = np.concatenate((a_resp_day0, a_nresp_day0), axis=0)  # Combine Day 0 data\n",
    "    data_day7 = np.concatenate((a_resp_day7, a_nresp_day7), axis=0)  # Combine Day 7 data\n",
    "\n",
    "    # Combine labels and gender information (assuming responders come first)\n",
    "    combined_labels = np.concatenate((responder_labels, non_responder_labels))\n",
    "    combined_sex = sex  # The `sex` vector already corresponds to responders and non-responders\n",
    "\n",
    "    return data_day0, data_day7, combined_labels, combined_sex\n",
    "\n",
    "# Example: Store the data efficiently\n",
    "def store_data_with_labels(data_day0, data_day7, combined_labels, combined_sex):\n",
    "    dataset = []\n",
    "    n_subjects = data_day0.shape[0]  # Total subjects (84 + 92)\n",
    "\n",
    "    # Store each subject's data, label, and gender in a dictionary\n",
    "    for subject_idx in range(n_subjects):\n",
    "        subject_data = {\n",
    "            \"day0_matrices\": data_day0[subject_idx, :, :, :],  # All 133 windows for day 0\n",
    "            \"day7_matrices\": data_day7[subject_idx, :, :, :],  # All 133 windows for day 7\n",
    "            \"responder_label\": combined_labels[subject_idx],  # 1 for responder, 0 for non-responder\n",
    "            \"gender\": combined_sex[subject_idx]  # 1 for male, 0 for female\n",
    "        }\n",
    "        dataset.append(subject_data)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Usage example\n",
    "data_day0, data_day7, combined_labels, combined_sex = get_combined_data()\n",
    "dataset = store_data_with_labels(data_day0, data_day7, combined_labels, combined_sex)\n",
    "\n",
    "# Now the 'dataset' contains all subject data with labels and gender for efficient access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e5246",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486a6ce3",
   "metadata": {},
   "source": [
    "# Understanding Vertex and Edge Labels in gSpan and Graph Mining Algorithms\n",
    "\n",
    "## Introduction\n",
    "In gSpan (and other graph mining algorithms), labels for vertices and edges serve a specific purpose:\n",
    "\n",
    "## Vertex Labels\n",
    "Vertex labels in a graph represent attributes or categories that distinguish different types of nodes in the graph. In your case, since you’re working with EEG channels, all the vertices (representing EEG channels) can have the same label because they are essentially the same kind of entity (i.e., EEG channels). However, in general, vertex labels are used to:\n",
    "\n",
    "- Differentiate nodes based on characteristics.\n",
    "- For example, in a social network, a vertex could represent a person, and the label could be the person’s profession or role (e.g., doctor, engineer, etc.).\n",
    "- In your case, because all EEG channels are similar in nature, you can assign the same label to all vertices. The label `2` is used as a placeholder since gSpan doesn’t allow labels `0` or `1` and all vertex labels should be larger than `1`.\n",
    "\n",
    "## Edge Labels\n",
    "Edge labels in a graph represent relationships or weights between nodes (vertices). In your case, the edges represent couplings between different EEG channels, and the edge label could indicate:\n",
    "\n",
    "- Strength of the connection: For example, the coupling between two EEG channels could be strong or weak, and you could encode these differences using different labels for edges.\n",
    "- Type of relationship: In some graphs, edges represent different types of connections (e.g., friend, colleague, family). In your case, however, the edges represent a quantitative measurement (the coupling value between EEG channels).\n",
    "\n",
    "## Specific Use in Your Context\n",
    "- **Vertex Labels:** In the coupling matrices, all vertices (EEG channels) can be labeled the same (e.g., label `2`) because they represent the same type of entity (EEG channels). If different types of nodes were involved, you might assign different labels.\n",
    "- **Edge Labels:** You are creating edges based on the coupling values between EEG channels. In your current setup, you are assigning a uniform label (`2`) to all edges for simplicity. However, you could refine the edge labels to reflect the strength of the coupling:\n",
    "    - For example, you could categorize coupling strengths into different bins (e.g., strong, medium, weak) and assign different labels based on these categories.\n",
    "\n",
    "## Why Are Labels Important in gSpan?\n",
    "- **Pattern Mining:** gSpan is used to find frequent subgraphs (patterns) in a set of graphs. The labels on vertices and edges are critical for pattern mining because gSpan looks for structural patterns that include these labels.\n",
    "    - For example, if the algorithm finds a subgraph with specific vertex labels and edge labels that appears frequently across multiple graphs, it considers it a frequent pattern.\n",
    "- **Distinguishing Graph Components:** The labels on the vertices and edges allow the algorithm to differentiate between different types of nodes and relationships. Without labels, gSpan would only be able to identify purely structural patterns, but with labels, it can find patterns based on both structure and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f9e7188-f032-4eab-a2e8-3167bb9e6fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t # 0\n",
      "v 0 2\n",
      "v 1 2\n",
      "v 2 2\n",
      "v 3 2\n",
      "v 4 2\n",
      "v 5 2\n",
      "v 6 2\n",
      "v 7 2\n",
      "v 8 2\n",
      "v 9 2\n",
      "v 10 2\n",
      "v 11 2\n",
      "v 12 2\n",
      "v 13 2\n",
      "v 14 2\n",
      "v 15 2\n",
      "v 16 2\n",
      "v 17 2\n",
      "v 18 2\n",
      "e 0 1 3\n",
      "e 0 3 3\n",
      "e 0 6 3\n",
      "e 0 9 3\n",
      "e 0 10 3\n",
      "e 0 11 3\n",
      "e 0 13 3\n",
      "e 0 14 3\n",
      "e 0 16 3\n",
      "e 0 17 5\n",
      "e 0 18 3\n",
      "e 1 2 3\n",
      "e 1 3 3\n",
      "e 1 4 3\n",
      "e 1 5 3\n",
      "e 1 6 3\n",
      "e 1 7 4\n",
      "e 1 8 3\n",
      "e 1 9 5\n",
      "e 1 10 4\n",
      "e 1 11 3\n",
      "e 1 18 3\n",
      "e 2 5 3\n",
      "e 2 7 3\n",
      "e 2 8 3\n",
      "e 2 10 3\n",
      "e 2 11 3\n",
      "e 2 12 3\n",
      "e 2 13 3\n",
      "e 2 15 3\n",
      "e 2 16 3\n",
      "e 2 18 3\n",
      "e 3 6 3\n",
      "e 3 8 3\n",
      "e 3 9 3\n",
      "e 3 11 3\n",
      "e 3 13 3\n",
      "e 3 14 3\n",
      "e 3 16 3\n",
      "e 4 5 3\n",
      "e 4 6 3\n",
      "e 4 12 3\n",
      "e 4 15 3\n",
      "e 4 18 3\n",
      "e 5 8 3\n",
      "e 5 11 3\n",
      "e 5 12 3\n",
      "e 5 13 3\n",
      "e 5 16 3\n",
      "e 5 17 3\n",
      "e 5 18 3\n",
      "e 6 8 3\n",
      "e 6 9 5\n",
      "e 6 10 3\n",
      "e 6 12 3\n",
      "e 6 15 3\n",
      "e 6 16 3\n",
      "e 6 17 5\n",
      "e 7 8 3\n",
      "e 7 9 3\n",
      "e 7 10 3\n",
      "e 7 11 3\n",
      "e 7 13 3\n",
      "e 7 14 3\n",
      "e 7 16 3\n",
      "e 7 18 3\n",
      "e 8 10 3\n",
      "e 8 12 3\n",
      "e 8 15 3\n",
      "e 8 17 5\n",
      "e 9 10 3\n",
      "e 9 12 3\n",
      "e 9 13 3\n",
      "e 9 14 3\n",
      "e 9 15 4\n",
      "e 9 16 3\n",
      "e 9 18 3\n",
      "e 10 12 3\n",
      "e 10 14 3\n",
      "e 10 16 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matrix_to_gspan_format(matrix, graph_id, vertex_label):\n",
    "    gspan_data = []\n",
    "    n_vertices = matrix.shape[0]\n",
    "    \n",
    "    # Add the graph ID\n",
    "    gspan_data.append(f\"t # {graph_id}\")\n",
    "    \n",
    "    # Add vertices with label for responder (3) or non-responder (2)\n",
    "    for i in range(n_vertices):\n",
    "        gspan_data.append(f\"v {i} {vertex_label}\")\n",
    "    \n",
    "    # Add edges (using upper triangle of the matrix, ignoring the diagonal)\n",
    "    for i in range(n_vertices):\n",
    "        for j in range(i + 1, n_vertices):\n",
    "            edge_weight = matrix[i, j]\n",
    "            if edge_weight > 0:  # Only include non-zero edges\n",
    "                # You can still use edge strength to assign a label\n",
    "                if edge_weight > 7:\n",
    "                    edge_label = 3  # Strong coupling\n",
    "                elif edge_weight > 4:\n",
    "                    edge_label = 4  # Medium coupling\n",
    "                else:\n",
    "                    edge_label = 5  # Weak coupling\n",
    "                gspan_data.append(f\"e {i} {j} {edge_label}\")\n",
    "    \n",
    "    return \"\\n\".join(gspan_data)\n",
    "\n",
    "def coupling_matrices_to_gspan(alpha_responder_day0, sex, responder_status):\n",
    "    gspan_formatted_data = []\n",
    "    \n",
    "    n_subjects = alpha_responder_day0.shape[0]\n",
    "    n_windows = alpha_responder_day0.shape[3]\n",
    "\n",
    "    graph_id = 0  # Starting graph ID\n",
    "    # Loop through subjects and windows\n",
    "    for subject_idx in range(n_subjects):\n",
    "        for window_idx in range(n_windows):\n",
    "            # Get the corresponding 19x19 coupling matrix\n",
    "            coupling_matrix = alpha_responder_day0[subject_idx, :, :, window_idx]\n",
    "            \n",
    "            # Assign label based on responder status or gender\n",
    "            # vertex_label = 3 for responders, 2 for non-responders\n",
    "            vertex_label = 3 if responder_status[subject_idx] == 1 else 2\n",
    "            \n",
    "            # Alternatively, you can use gender for vertex labels\n",
    "            # vertex_label = 3 for male, 2 for female\n",
    "            # vertex_label = 3 if sex[subject_idx] == 1 else 2\n",
    "            \n",
    "            # Convert the matrix to gSpan format\n",
    "            gspan_data = matrix_to_gspan_format(coupling_matrix, graph_id, vertex_label)\n",
    "            gspan_formatted_data.append(gspan_data)\n",
    "            graph_id += 1\n",
    "    \n",
    "    # Add the final line to terminate the file\n",
    "    gspan_formatted_data.append(\"t # -1\")\n",
    "    \n",
    "    return \"\\n\".join(gspan_formatted_data)\n",
    "\n",
    "# Example: Convert the data to gSpan format and print 10 samples\n",
    "responder_status = np.random.randint(0, 2, 84)  # Mock responder status for 84 subjects (1 = responder, 0 = non-responder)\n",
    "gspan_output = coupling_matrices_to_gspan(a_resp_day0, sex, responder_status)\n",
    "\n",
    "# Print first 10 graphs generated\n",
    "gspan_output_lines = gspan_output.split(\"\\n\")\n",
    "for i in range(100):  # Print first 100 lines (approx. 10 graphs)\n",
    "    print(gspan_output_lines[i])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bbec06-9c8c-47e0-ab83-9ebd538293e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
